"""
ë©”ì¸ íŒŒì´í”„ë¼ì¸ - ê³ ìš©24 APIì—ì„œ ê³¼ì • ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì½˜í…ì¸ ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
  python pipeline.py                    # ì „ì²´ ì‹¤í–‰ (API í˜¸ì¶œ + ì½˜í…ì¸  ìƒì„±)
  python pipeline.py --json data.json   # JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ

ì˜ì¡´ì„±:
  pip install requests beautifulsoup4 Pillow

v4 ë³€ê²½ì‚¬í•­:
- 3ë‹¨ê³„ ë°ì´í„° í™•ë³´: L01(ëª©ë¡) â†’ L02(ìƒì„¸) â†’ í¬ë¡¤ë§(í›ˆë ¨ëª©í‘œ)
- ê³¼ì • ìƒì„¸ í˜ì´ì§€ì—ì„œ í›ˆë ¨ëª©í‘œ/ê³¼ì • ê°•ì  ìë™ í¬ë¡¤ë§
- ì¹´ë“œë‰´ìŠ¤ 2ë²ˆ ìŠ¬ë¼ì´ë“œ í•­ìƒ ìƒì„± (í›ˆë ¨ëª©í‘œ â†’ ì»¤ë¦¬í˜ëŸ¼ â†’ fallback)
"""

import json
import os
import re
import sys
from datetime import datetime, timedelta

from generate_cardnews import generate_cardnews
from generate_blog import generate_blog_post

# v2 ì¹´ë“œë‰´ìŠ¤ (ì´ë¯¸ì§€ ë°°ê²½) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
try:
    from generate_cardnews_v2 import generate_cardnews_v2
    HAS_V2 = True
except ImportError:
    HAS_V2 = False

# â”€â”€ ì˜ì¡´ì„± ìë™ ì„¤ì¹˜ â”€â”€
def _ensure_bs4():
    """beautifulsoup4ê°€ ì—†ìœ¼ë©´ ìë™ ì„¤ì¹˜"""
    try:
        from bs4 import BeautifulSoup  # noqa: F401
        return True
    except ImportError:
        print("  ğŸ“¦ beautifulsoup4 ë¯¸ì„¤ì¹˜ â†’ ìë™ ì„¤ì¹˜ ì¤‘...")
        import subprocess
        try:
            subprocess.check_call(
                [sys.executable, "-m", "pip", "install", "beautifulsoup4"],
                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )
            print("  âœ… beautifulsoup4 ì„¤ì¹˜ ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"  âŒ ì„¤ì¹˜ ì‹¤íŒ¨: {e}")
            print("  â†’ ìˆ˜ë™ ì„¤ì¹˜ í•„ìš”: pip install beautifulsoup4")
            return False

HAS_BS4 = _ensure_bs4()

# â”€â”€ ì„¤ì • â”€â”€
OUTPUT_DIR = "output"
PROCESSED_FILE = "output/.processed_courses.json"


def load_processed_ids():
    """ì´ë¯¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•œ ê³¼ì • ëª©ë¡ì„ ë¡œë“œ"""
    if os.path.exists(PROCESSED_FILE):
        with open(PROCESSED_FILE, "r") as f:
            return json.load(f)
    return {}


def save_processed_ids(processed):
    """ì²˜ë¦¬ ì™„ë£Œëœ ê³¼ì • ì €ì¥"""
    os.makedirs(os.path.dirname(PROCESSED_FILE), exist_ok=True)
    with open(PROCESSED_FILE, "w") as f:
        json.dump(processed, f, ensure_ascii=False, indent=2)


def make_course_key(course):
    """ê³¼ì •ì˜ ê³ ìœ  í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    parts = []
    course_id = course.get("trprId", course.get("id", ""))
    if course_id:
        parts.append(str(course_id))
    degr = course.get("trprDegr", "")
    if degr:
        parts.append(str(degr))
    start = course.get("traStartDate", "")
    end = course.get("traEndDate", "")
    if start:
        parts.append(start)
    if end:
        parts.append(end)
    if not start and not end and course.get("period"):
        period_clean = course["period"].replace(".", "").replace(" ", "")
        parts.append(period_clean[:20])
    if not parts:
        parts.append(course.get("title", "unknown"))
        parts.append(course.get("institution", ""))
    return "_".join(parts)


def format_date(raw):
    """API ì‘ë‹µì˜ ë‚ ì§œ ë¬¸ìì—´ì„ YYYY.MM.DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not raw:
        return ""
    raw = str(raw).strip()
    if re.match(r"^\d{8}$", raw):
        return f"{raw[:4]}.{raw[4:6]}.{raw[6:8]}"
    if re.match(r"^\d{4}-\d{2}-\d{2}", raw):
        return raw[:10].replace("-", ".")
    return raw


def fetch_courses_from_api():
    """
    ê³ ìš©24 APIì—ì„œ ì œì£¼ì§€ì—­ íŠ¹í™”í›ˆë ¨ ê³¼ì •ì„ 2ë‹¨ê³„ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.

    1ë‹¨ê³„: L01(ëª©ë¡ API) â†’ ê³¼ì • ë¦¬ìŠ¤íŠ¸ + trprId, trprDegr, instCd í™•ë³´
    2ë‹¨ê³„: L02(ê³¼ì •/ê¸°ê´€ì •ë³´ API) â†’ ê³¼ì •ë³„ trtm(ì´í›ˆë ¨ì‹œê°„), ncsNm(NCSì§ì¢…ëª…) ë“± ìƒì„¸

    â€» 3ë‹¨ê³„(í›ˆë ¨ëª©í‘œ í¬ë¡¤ë§)ëŠ” enrich_training_goals()ì—ì„œ ë³„ë„ ì‹¤í–‰
    """
    import requests
    import time

    api_key = os.environ.get("HRD_API_KEY", "")
    if not api_key:
        print("  âŒ HRD_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1ë‹¨ê³„: L01 ëª©ë¡ API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    url_list = "https://www.work24.go.kr/cm/openApi/call/hr/callOpenApiSvcInfo310L01.do"

    today = datetime.now()
    end_date = today + timedelta(days=180)

    params_list = {
        "authKey": api_key,
        "returnType": "JSON",
        "outType": "1",
        "pageNum": "1",
        "pageSize": "100",
        "srchTraStDt": today.strftime("%Y%m%d"),
        "srchTraEndDt": end_date.strftime("%Y%m%d"),
        "srchTraArea1": "50",
        "crseTracseSe": "C0102",
        "sort": "ASC",
        "sortCol": "2",
    }

    try:
        print("  [1ë‹¨ê³„] L01 ëª©ë¡ API í˜¸ì¶œ ì¤‘...")
        response = requests.get(url_list, params=params_list, timeout=30)
        print(f"  ì‘ë‹µ ì½”ë“œ: {response.status_code}")

        content_type = response.headers.get("Content-Type", "")
        if "text/html" in content_type:
            print(f"  âš ï¸  HTML ì‘ë‹µ ìˆ˜ì‹  â€” API URLì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì¸ì¦í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"  ì‘ë‹µ ì• 300ì:\n{response.text[:300]}")
            return []

        data = response.json()

        srch_list = data.get("srchList", [])
        if not srch_list:
            srch_list = data.get("scn_list", data.get("returnList", []))

        if not srch_list:
            print("  âš ï¸  ëª©ë¡ API ê²°ê³¼ 0ê±´")
            return []

        # ì²« ë²ˆì§¸ ì•„ì´í…œ í‚¤ ë¤í”„ (ë””ë²„ê·¸)
        first = srch_list[0]
        print(f"\n  â”Œâ”€ [DEBUG] L01 ëª©ë¡ API í•„ë“œ ({len(first)}ê°œ) â”€â”")
        for k, v in first.items():
            val_str = str(v)[:60] if v else "(ë¹ˆê°’)"
            print(f"  â”‚  {k:25s} = {val_str}")
        print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        print(f"  L01ì—ì„œ {len(srch_list)}ê°œ ê³¼ì • ì¡°íšŒ ì™„ë£Œ\n")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2ë‹¨ê³„: L02 ê³¼ì •/ê¸°ê´€ì •ë³´ API (ê³¼ì •ë³„ ìƒì„¸)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        url_detail = "https://www.work24.go.kr/cm/openApi/call/hr/callOpenApiSvcInfo310L02.do"
        print("  [2ë‹¨ê³„] L02 ìƒì„¸ APIë¡œ í›ˆë ¨ì‹œê°„/NCSì§ì¢… ì¡°íšŒ ì¤‘...")

        courses = []
        for idx, item in enumerate(srch_list):
            course = _parse_list_item(item)
            if not course:
                continue

            trpr_id = course["trprId"]
            trpr_degr = course["trprDegr"]
            torg_id = _get_field(item, "instCd", "trainstCstId", "torgId",
                                  "INST_CD", "TRAINST_CST_ID", "TORG_ID",
                                  "instIno", "INST_INO")

            if trpr_id and trpr_degr and torg_id:
                detail = _fetch_course_detail(
                    api_key, url_detail, trpr_id, trpr_degr, torg_id,
                    is_first=(idx == 0)
                )
                if detail:
                    course["totalHours"] = detail.get("totalHours", 0)
                    course["ncsName"] = detail.get("ncsName", "")
                    # L02ì—ì„œ ncsCdê°€ í™•ë³´ë˜ë©´ ë®ì–´ì“°ê¸° (ë” ì •í™•)
                    if detail.get("ncsCd"):
                        course["ncsCd"] = detail["ncsCd"]
                    if not course.get("address") and detail.get("address"):
                        course["address"] = detail["address"]

                time.sleep(0.3)
            else:
                if idx == 0:
                    print(f"  âš ï¸  í›ˆë ¨ê¸°ê´€IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ â€” L01 í‚¤ ëª©ë¡ì—ì„œ ê¸°ê´€ID í•„ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")

            courses.append(course)

        has_hours = sum(1 for c in courses if c.get("totalHours", 0) > 0)
        has_ncs = sum(1 for c in courses if c.get("ncsName", ""))
        has_ncs_cd = sum(1 for c in courses if c.get("ncsCd", ""))
        print(f"\n  âœ… ì´ {len(courses)}ê°œ ê³¼ì • (í›ˆë ¨ì‹œê°„ {has_hours}ê±´, NCSì§ì¢… {has_ncs}ê±´, NCSì½”ë“œ {has_ncs_cd}ê±´ í™•ë³´)")

        return courses

    except requests.exceptions.JSONDecodeError:
        print(f"  âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨ â€” API ì‘ë‹µì´ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
        print(f"  ì‘ë‹µ ì• 500ì:\n{response.text[:500]}")
        return []
    except Exception as e:
        print(f"  API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return []


def _fetch_course_detail(api_key, url, trpr_id, trpr_degr, torg_id, is_first=False):
    """
    L02 ê³¼ì •/ê¸°ê´€ì •ë³´ APIë¡œ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    ë°˜í™˜ê°’: {"totalHours": int, "ncsName": str, "ncsCd": str, ...} ë˜ëŠ” None
    """
    import requests

    params = {
        "authKey": api_key,
        "returnType": "JSON",
        "outType": "2",
        "srchTrprId": trpr_id,
        "srchTrprDegr": trpr_degr,
        "srchTorgId": torg_id,
    }

    try:
        resp = requests.get(url, params=params, timeout=15)
        if resp.status_code != 200:
            return None

        data = resp.json()

        base_info = data.get("inst_base_info", data.get("instBaseInfo", {}))
        if isinstance(base_info, list):
            base_info = base_info[0] if base_info else {}

        if is_first and base_info:
            print(f"\n  â”Œâ”€ [DEBUG] L02 ìƒì„¸ API inst_base_info í•„ë“œ ({len(base_info)}ê°œ) â”€â”")
            for k, v in base_info.items():
                val_str = str(v)[:60] if v else "(ë¹ˆê°’)"
                print(f"  â”‚  {k:25s} = {val_str}")
            print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        if not base_info:
            base_info = data

        # trtm ì¶”ì¶œ
        raw_trtm = _get_field(base_info, "trtm", "TRTM", "tRtM")
        try:
            total_hours = int(raw_trtm)
        except (ValueError, TypeError):
            total_hours = 0

        # ncsNm ì¶”ì¶œ
        ncs_name = _get_field(base_info, "ncsNm", "NCS_NM", "ncsNM", "ncsnm")

        # ncsCd ì¶”ì¶œ (seo_helper v4 NCS ê¸°ë°˜ ë¶„ì•¼ ê°ì§€ìš©)
        ncs_cd = _get_field(base_info, "ncsCd", "NCS_CD", "ncscd", "ncsCdArr")

        if is_first:
            print(f"  [DEBUG] L02 â†’ í›ˆë ¨ì‹œê°„: {total_hours}, NCSì§ì¢…: {ncs_name}, NCSì½”ë“œ: {ncs_cd}")
            print()

        return {
            "totalHours": total_hours,
            "ncsName": ncs_name,
            "ncsCd": ncs_cd,
            "address": " ".join(filter(None, [
                _get_field(base_info, "addr1", "ADDR1"),
                _get_field(base_info, "addr2", "ADDR2"),
            ])),
        }

    except Exception as e:
        return None


def enrich_training_goals(courses):
    """ê³¼ì • ëª©ë¡ì— í›ˆë ¨ëª©í‘œ/ê³¼ì •ê°•ì ì„ í¬ë¡¤ë§í•˜ì—¬ ì±„ì›ë‹ˆë‹¤."""
    import time

    need_crawl = [c for c in courses
                  if c.get("hrd_url") and not c.get("trainingGoal")]

    if not need_crawl:
        already = sum(1 for c in courses if c.get("trainingGoal"))
        if already:
            print(f"  âœ… í›ˆë ¨ëª©í‘œ {already}ê±´ ì´ë¯¸ í™•ë³´ë¨ (í¬ë¡¤ë§ ìŠ¤í‚µ)")
        else:
            print("  âš ï¸  hrd_urlì´ ì—†ì–´ í¬ë¡¤ë§í•  ìˆ˜ ì—†ìŒ")
        return

    print(f"  [3ë‹¨ê³„] ê³¼ì • ìƒì„¸ í˜ì´ì§€ì—ì„œ í›ˆë ¨ëª©í‘œ í¬ë¡¤ë§ ì¤‘... ({len(need_crawl)}ê±´)")

    if not HAS_BS4:
        print("  âŒ beautifulsoup4 ì„¤ì¹˜ ì‹¤íŒ¨ â€” í›ˆë ¨ëª©í‘œ í¬ë¡¤ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return

    goal_count = 0
    for idx, course in enumerate(need_crawl):
        hrd_url = course.get("hrd_url", "")
        goal_data = _fetch_training_goal(hrd_url, is_first=(idx == 0))
        if goal_data:
            course["trainingGoal"] = goal_data.get("trainingGoal", "")
            course["courseStrength"] = goal_data.get("courseStrength", "")
            if course["trainingGoal"]:
                goal_count += 1
        time.sleep(0.5)

    total_goals = sum(1 for c in courses if c.get("trainingGoal"))
    print(f"  âœ… í›ˆë ¨ëª©í‘œ {total_goals}ê±´ í™•ë³´ (ì´ë²ˆ í¬ë¡¤ë§: {goal_count}ê±´)")


def _fetch_training_goal(hrd_url, is_first=False):
    """ê³ ìš©24 ê³¼ì • ìƒì„¸ í˜ì´ì§€ì—ì„œ í›ˆë ¨ëª©í‘œ/í›ˆë ¨ê³¼ì • ê°•ì ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    import requests

    if not HAS_BS4:
        if is_first:
            print("  âš ï¸  beautifulsoup4 ì‚¬ìš© ë¶ˆê°€ â€” í¬ë¡¤ë§ ê±´ë„ˆëœ€")
        return None

    attempts = [
        {
            "url": hrd_url,
            "ua": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/120.0.0.0 Safari/537.36"),
            "label": "www",
        },
        {
            "url": hrd_url.replace("www.work24.go.kr", "m.work24.go.kr"),
            "ua": ("Mozilla/5.0 (Linux; Android 13) "
                   "AppleWebKit/537.36 (KHTML, like Gecko) "
                   "Chrome/120.0.0.0 Mobile Safari/537.36"),
            "label": "mobile",
        },
    ]

    for attempt in attempts:
        try:
            headers = {
                "User-Agent": attempt["ua"],
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
            }
            resp = requests.get(attempt["url"], headers=headers, timeout=15,
                                allow_redirects=True)
            if is_first:
                print(f"  [DEBUG] í¬ë¡¤ë§ ì‹œë„ ({attempt['label']}): {resp.status_code} "
                      f"({len(resp.text)}ì)")
            if resp.status_code != 200:
                if is_first:
                    print(f"  âš ï¸  {attempt['label']} â†’ HTTP {resp.status_code}")
                continue
            result = _parse_training_goal_html(resp.text, is_first)
            if result and result.get("trainingGoal"):
                return result
            if is_first:
                print(f"  âš ï¸  {attempt['label']} â†’ HTMLì—ì„œ í›ˆë ¨ëª©í‘œë¥¼ ì°¾ì§€ ëª»í•¨")
        except requests.exceptions.Timeout:
            if is_first:
                print(f"  âš ï¸  {attempt['label']} â†’ íƒ€ì„ì•„ì›ƒ (15ì´ˆ)")
        except requests.exceptions.ConnectionError as e:
            if is_first:
                err_msg = str(e)[:80]
                print(f"  âš ï¸  {attempt['label']} â†’ ì—°ê²° ì‹¤íŒ¨: {err_msg}")
        except Exception as e:
            if is_first:
                print(f"  âš ï¸  {attempt['label']} â†’ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    return None


def _parse_training_goal_html(html_text, is_first=False):
    """HTMLì—ì„œ í›ˆë ¨ëª©í‘œ/ê³¼ì • ê°•ì ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
    from bs4 import BeautifulSoup

    soup = BeautifulSoup(html_text, "html.parser")
    training_goal = ""
    course_strength = ""

    for th in soup.find_all("th"):
        th_text = th.get_text(strip=True)
        if th_text == "í›ˆë ¨ëª©í‘œ":
            td = th.find_next_sibling("td")
            if not td:
                tr = th.find_parent("tr")
                if tr:
                    td = tr.find("td")
            if td:
                training_goal = td.get_text(separator="\n", strip=True)
        elif "í›ˆë ¨ê³¼ì •ì˜ ê°•ì " in th_text or "í›ˆë ¨ê³¼ì •ì˜ê°•ì " in th_text:
            td = th.find_next_sibling("td")
            if not td:
                tr = th.find_parent("tr")
                if tr:
                    td = tr.find("td")
            if td:
                course_strength = td.get_text(separator="\n", strip=True)

    if not training_goal:
        for elem in soup.find_all(string=lambda t: t and "í›ˆë ¨ëª©í‘œ" in t):
            parent = elem.find_parent("th") or elem.find_parent("dt") or elem.find_parent("strong")
            if parent:
                next_td = parent.find_next(["td", "dd"])
                if next_td:
                    training_goal = next_td.get_text(separator="\n", strip=True)
                    break

    if is_first:
        goal_preview = training_goal[:80] + "..." if len(training_goal) > 80 else training_goal
        print(f"  [DEBUG] íŒŒì‹± â†’ í›ˆë ¨ëª©í‘œ: {goal_preview or '(ì—†ìŒ)'}")
        print(f"  [DEBUG] íŒŒì‹± â†’ ê³¼ì • ê°•ì : {'ìˆìŒ (' + str(len(course_strength)) + 'ì)' if course_strength else '(ì—†ìŒ)'}")

    return {
        "trainingGoal": training_goal,
        "courseStrength": course_strength,
    }


def format_cost(raw_value):
    """ìˆ«ì ë¬¸ìì—´ì„ '1,077,960ì›' í˜•íƒœë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
    if not raw_value:
        return ""
    try:
        return f"{int(raw_value):,}ì›"
    except (ValueError, TypeError):
        return f"{raw_value}ì›"


def _get_field(item, *keys):
    """API ì‘ë‹µì—ì„œ ì—¬ëŸ¬ ê°€ëŠ¥í•œ í‚¤ ì´ë¦„ì„ ì‹œë„í•˜ì—¬ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    for key in keys:
        val = item.get(key, "")
        if val not in ("", None):
            return val
    return ""


def _parse_list_item(api_item):
    """
    L01 ëª©ë¡ API ì•„ì´í…œì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    (trtm, ncsNmì€ L02ì—ì„œ ë³„ë„ ì±„ì›€)
    """
    try:
        start_raw = _get_field(api_item, "traStartDate", "TRA_START_DATE")
        end_raw = _get_field(api_item, "traEndDate", "TRA_END_DATE")

        start_fmt = format_date(start_raw)
        end_fmt = format_date(end_raw)
        period = f"{start_fmt} ~ {end_fmt}" if start_fmt and end_fmt else ""

        institution = _get_field(api_item, "subTitle", "SUB_TITLE", "instNm", "INST_NM", "inoNm", "INO_NM")
        trpr_id = _get_field(api_item, "trprId", "TRPR_ID")
        trpr_degr = _get_field(api_item, "trprDegr", "TRPR_DEGR")

        raw_course_man = _get_field(api_item, "courseMan", "COURSE_MAN")
        course_cost = format_cost(raw_course_man)

        try:
            self_cost = format_cost(str(round(int(raw_course_man) * 0.1)))
        except (ValueError, TypeError):
            self_cost = ""

        return {
            "trprId": trpr_id,
            "trprDegr": trpr_degr,
            "traStartDate": str(start_raw),
            "traEndDate": str(end_raw),
            "title": _get_field(api_item, "title", "TITLE", "trprNm", "TRPR_NM"),
            "ncsName": "",          # L02ì—ì„œ ì±„ì›Œì§
            "ncsCd": _get_field(api_item, "ncsCd", "NCS_CD", "ncscd"),  # NCS ì§ë¬´ë¶„ë¥˜ ì½”ë“œ (L01ì—ì„œ 1ì°¨, L02ì—ì„œ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ)
            "institution": institution,
            "period": period,
            "courseCost": course_cost,
            "selfCost": self_cost,
            "totalHours": 0,        # L02ì—ì„œ ì±„ì›Œì§
            "capacity": f"{_get_field(api_item, 'yardMan', 'YARD_MAN') or '?'}ëª…",
            "target": "êµ­ë¯¼ë‚´ì¼ë°°ì›€ì¹´ë“œ ìˆìœ¼ë©´ ëˆ„êµ¬ë‚˜",
            "benefits": "",
            "curriculum": [],
            "trainingGoal": "",      # 3ë‹¨ê³„ í¬ë¡¤ë§ì—ì„œ ì±„ì›Œì§
            "courseStrength": "",     # 3ë‹¨ê³„ í¬ë¡¤ë§ì—ì„œ ì±„ì›Œì§
            "outcome": "",
            "contact": f"{institution} Tel: {_get_field(api_item, 'telNo', 'TEL_NO', 'trprChapTel', 'TRPR_CHAP_TEL')}",
            "address": " ".join(filter(None, [
                _get_field(api_item, "addr1", "ADDR1"),
                _get_field(api_item, "addr2", "ADDR2"),
            ])),
            "hrd_url": (
                f"https://www.work24.go.kr/hr/a/a/3100/selectTracseDetl.do"
                f"?tracseId={trpr_id}"
                f"&tracseTme={trpr_degr}"
                f"&crseTracseSe=C0102"
            ),
        }

    except Exception as e:
        print(f"  ê³¼ì • íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None


def generate_content_for_course(course, output_dir):
    """ë‹¨ì¼ ê³¼ì •ì— ëŒ€í•´ ì¹´ë“œë‰´ìŠ¤ + ë¸”ë¡œê·¸ + ì¸ìŠ¤íƒ€ ìº¡ì…˜ + ë¦´ìŠ¤ ëŒ€ë³¸ + ê²Œì‹œ ê°€ì´ë“œë¥¼ ìƒì„±"""
    print(f"\n{'â”€' * 50}")
    print(f"  ğŸ“Œ {course['title']}")
    if course.get("period"):
        print(f"  ğŸ“… ({course['period']})")
    print(f"{'â”€' * 50}")

    use_v2 = HAS_V2 and os.environ.get("PEXELS_API_KEY", "")
    if use_v2:
        cardnews_paths = generate_cardnews_v2(course, output_dir)
    else:
        cardnews_paths = generate_cardnews(course, output_dir)

    blog_md, blog_html = generate_blog_post(course, output_dir)

    safe_name = course["title"][:30].replace(" ", "_").replace("/", "_")
    caption_path = os.path.join(output_dir, f"{safe_name}_instagram_caption.txt")
    reels_path = os.path.join(output_dir, f"{safe_name}_reels_script.txt")
    sora_path = os.path.join(output_dir, f"{safe_name}_reels_sora.txt")
    vrew_path = os.path.join(output_dir, f"{safe_name}_reels_vrew.txt")
    guide_path = os.path.join(output_dir, f"{safe_name}_posting_guide.txt")

    return {
        "cardnews": cardnews_paths,
        "blog_md": blog_md,
        "blog_html": blog_html,
        "instagram_caption": caption_path if os.path.exists(caption_path) else None,
        "reels_script": reels_path if os.path.exists(reels_path) else None,
        "reels_sora": sora_path if os.path.exists(sora_path) else None,
        "reels_vrew": vrew_path if os.path.exists(vrew_path) else None,
        "posting_guide": guide_path if os.path.exists(guide_path) else None,
    }


def run_pipeline(courses):
    """ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    processed = load_processed_ids()
    new_count = 0
    skip_count = 0

    for course in courses:
        course_key = make_course_key(course)

        if course_key in processed:
            print(f"  â­ï¸  ì´ë¯¸ ì²˜ë¦¬ë¨: {course['title'][:40]} ({course.get('period', '')})")
            skip_count += 1
            continue

        result = generate_content_for_course(course, OUTPUT_DIR)

        processed[course_key] = {
            "title": course["title"],
            "period": course.get("period", ""),
            "generated_at": datetime.now().isoformat(),
            "files": result,
        }
        new_count += 1

    save_processed_ids(processed)

    print(f"\n{'=' * 60}")
    print(f"  âœ… ì‹¤í–‰ ê²°ê³¼: ìƒˆ ê³¼ì • {new_count}ê±´ ìƒì„±, {skip_count}ê±´ ìŠ¤í‚µ")
    if skip_count > 0:
        print(f"  ğŸ’¡ ìŠ¤í‚µëœ ê³¼ì •ì„ ì¬ìƒì„±í•˜ë ¤ë©´: python pipeline.py --force")
    print(f"{'=' * 60}")

    if new_count > 0:
        print(f"\n  ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}/")
        print(f"  ê³¼ì •ë‹¹ ìƒì„± íŒŒì¼:")
        print(f"    - *_blog.md           : ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë§ˆí¬ë‹¤ìš´ (SEO ìµœì í™”)")
        print(f"    - *_blog_naver.html   : ë„¤ì´ë²„ ë¸”ë¡œê·¸ HTML (ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ìš©)")
        print(f"    - *_1_cover.png       : ì¹´ë“œë‰´ìŠ¤ ì»¤ë²„ ì´ë¯¸ì§€")
        print(f"    - *_2_detail.png      : ì¹´ë“œë‰´ìŠ¤ ìƒì„¸ ì´ë¯¸ì§€")
        print(f"    - *_3_howto.png       : ì¹´ë“œë‰´ìŠ¤ ì‹ ì²­ë°©ë²• ì´ë¯¸ì§€")
        print(f"    - *_instagram_caption.txt : ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ + í•´ì‹œíƒœê·¸")
        print(f"    - *_reels_script.txt  : ë¦´ìŠ¤ ëŒ€ë³¸ (í•„ìˆ˜ ìš”ì†Œ + ì›Œí¬í”Œë¡œ)")
        print(f"    - *_reels_sora.txt    : Sora ì»· ì‹œë‚˜ë¦¬ì˜¤ (ì˜ìƒë§Œ, ìë§‰ ì—†ìŒ)")
        print(f"    - *_reels_vrew.txt    : Vrew ìë§‰ ì›ê³  (íƒ€ì„ì½”ë“œ + í…ìŠ¤íŠ¸)")
        print(f"    - *_posting_guide.txt : ê²Œì‹œ íƒ€ì´ë°/ì‹œë¦¬ì¦ˆ ì „ëµ ê°€ì´ë“œ")

    return new_count


if __name__ == "__main__":
    print("=" * 60)
    print("  ğŸš€ íŠ¹í™”í›ˆë ¨ ì½˜í…ì¸  ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸ v4")
    print(f"  ğŸ“… ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("  ğŸ¯ ëŒ€ìƒ: ì‚°ì—…êµ¬ì¡°ë³€í™”ëŒ€ì‘ ë“± íŠ¹í™”í›ˆë ¨ (C0102) / ì œì£¼")
    print("=" * 60)

    if "--force" in sys.argv:
        cache_file = os.path.join(OUTPUT_DIR, "processed_ids.json")
        if os.path.exists(cache_file):
            os.remove(cache_file)
            print("\n  ğŸ”„ --force: ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ â†’ ì „ì²´ ê³¼ì • ì¬ìƒì„±í•©ë‹ˆë‹¤")
        else:
            print("\n  ğŸ”„ --force: ìºì‹œ ì—†ìŒ â†’ ì „ì²´ ê³¼ì • ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤")

    if "--json" in sys.argv:
        json_idx = sys.argv.index("--json") + 1
        json_path = sys.argv[json_idx]
        print(f"\n  JSON íŒŒì¼ì—ì„œ ë¡œë“œ: {json_path}\n")
        with open(json_path, "r", encoding="utf-8") as f:
            courses = json.load(f)
    else:
        print("\n  ê³ ìš©24 APIì—ì„œ ë°ì´í„° ì¡°íšŒ ì¤‘...\n")
        courses = fetch_courses_from_api()

    if courses:
        # â”€â”€ í›ˆë ¨ëª©í‘œ í¬ë¡¤ë§ (API/JSON ëª¨ë“œ ëª¨ë‘) â”€â”€
        enrich_training_goals(courses)
        print()

        # ì²« ë²ˆì§¸ ê³¼ì • íŒŒì‹± ê²°ê³¼ ìš”ì•½
        c = courses[0]
        print(f"  â”€â”€ ì²« ë²ˆì§¸ ê³¼ì • íŒŒì‹± ê²°ê³¼ í™•ì¸ â”€â”€")
        print(f"  ê³¼ì •ëª…:     {c.get('title', '?')}")
        print(f"  NCSì§ì¢…ëª…:  {c.get('ncsName') or 'âŒ ë¹„ì–´ìˆìŒ (API í•„ë“œëª… í™•ì¸ í•„ìš”)'}")
        print(f"  NCSì½”ë“œ:    {c.get('ncsCd') or 'âŒ ë¹„ì–´ìˆìŒ (ë¶„ì•¼ ê°ì§€ê°€ ì œëª© ê¸°ë°˜ìœ¼ë¡œ ë™ì‘)'}")
        print(f"  í›ˆë ¨ì‹œê°„:   {c.get('totalHours') or 'âŒ 0 (API í•„ë“œëª… í™•ì¸ í•„ìš”)'}")
        print(f"  í›ˆë ¨ëª©í‘œ:   {(c.get('trainingGoal', '')[:50] + '...') if c.get('trainingGoal') else 'âŒ ë¹„ì–´ìˆìŒ (í¬ë¡¤ë§ í™•ì¸ í•„ìš”)'}")
        print(f"  ê¸°ê´€ëª…:     {c.get('institution', '?')}")
        print(f"  ìˆ˜ê°•ë¹„:     {c.get('courseCost', '?')}")
        print()
        run_pipeline(courses)
    else:
        print("  ìƒì„±í•  ê³¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
